# Titanic Survival Prediction with MLP

## Neural Networks 2025.1  

This project performs prediction of Titanic passengers' survival using **MLPs (Multi-Layer Perceptrons)** implemented in **PyTorch**, with comparative experiments between different architectures, activation functions, and optimizers.

---

## üìÇ Project Structure

- `train.csv` : Training dataset with survival labels (`Survived`).  
- `test.csv` : Test dataset without survival labels.  
- `results/` : Folder generated by the project containing:
  - Trained models (`*.pth`)  
  - Training histories (`*_history.json`)  
  - Final model comparison (`model_comparison.csv`)  

- `notebook.ipynb` : Main notebook with preprocessing, training, evaluation, and experiment visualization.  

---

## üõ† Technologies Used

- Python 3.x  
- Pandas, Numpy  
- Matplotlib, Seaborn  
- Scikit-learn (preprocessing and metrics)  
- PyTorch (MLP, training and evaluation)  
- tqdm (progress bar)

---

## üîç Project Pipeline

1. **Data Preprocessing**  
   - Handling missing values (`Age`, `Fare`, `Embarked`, `Cabin`)  
   - Creating new features (`FamilySize`, `IsAlone`, `Title`)  
   - Converting categorical variables and removing irrelevant columns (`PassengerId`, `Name`, `Ticket`)  

2. **Dataset Splitting**  
   - Separation into training, validation, and test sets  

3. **Creating DataLoaders**  
   - Preparing datasets in batches for training and validation  

4. **Defining and Training MLP Models**  
   - Comparative architectures: `Baseline`, `DeeperNet`, and `WideNet`  
   - Activation functions: ReLU, LeakyReLU, Tanh  
   - Optimizers: Adam, RMSprop  
   - Dropout and LayerNorm for regularization  

5. **Metrics Monitoring**  
   - Loss (CrossEntropy) and accuracy for training and validation  
   - Early stopping to prevent overfitting  
   - Learning rate scheduler (`ReduceLROnPlateau`)  

6. **Final Evaluation and Model Comparison**  
   - Comparison of loss and accuracy  
   - Learning rate evolution  
   - Saving models and training histories  

---

## ‚öô Model Configuration

Example of a model configuration:

```python
{
    "name": "Baseline",
    "input_size": 9,
    "num_classes": 2,
    "layer_sizes": [64, 32],
    "activation_fn": nn.ReLU(),
    "dropout_rate": 0.3,
    "learning_rate": 1e-3,
    "optimizer": torch.optim.Adam,
    "n_epochs": 100,
    "bs_train": 32,
    "bs_val_test": 64,
    "loss_fn": nn.CrossEntropyLoss(),
    "patience": 10
}
