# Predi√ß√£o de Sobreviv√™ncia no Titanic com MLP

## Redes Neurais 2025.1  

Este projeto realiza a predi√ß√£o da sobreviv√™ncia dos passageiros do Titanic utilizando **MLPs (Multi-Layer Perceptrons)** implementadas em **PyTorch**, com experimentos comparativos entre diferentes arquiteturas, fun√ß√µes de ativa√ß√£o e otimizadores.

---

## üìÇ Estrutura do Projeto

- `train.csv` : Conjunto de dados de treinamento com r√≥tulos de sobreviv√™ncia (`Survived`).  
- `test.csv` : Conjunto de dados de teste sem r√≥tulos de sobreviv√™ncia.  
- `results/` : Pasta gerada pelo projeto contendo:
  - Modelos treinados (`*.pth`)  
  - Hist√≥ricos de treinamento (`*_history.json`)  
  - Comparativo final dos modelos (`model_comparison.csv`)  

- `notebook.ipynb` : Notebook principal com pr√©-processamento, treino, avalia√ß√£o e visualiza√ß√£o dos experimentos.  

---

## üõ† Tecnologias Utilizadas

- Python 3.x  
- Pandas, Numpy  
- Matplotlib, Seaborn  
- Scikit-learn (pr√©-processamento e m√©tricas)  
- PyTorch (MLP, treino e avalia√ß√£o)  
- tqdm (barra de progresso)

---

## üîç Pipeline do Projeto

1. **Pr√©-processamento de dados**  
   - Tratamento de valores ausentes (`Age`, `Fare`, `Embarked`)  
   - Cria√ß√£o de novas features (`FamilySize`, `IsAlone`, `Title`)  
   - Convers√£o de vari√°veis categ√≥ricas e remo√ß√£o de colunas irrelevantes (`PassengerId`, `Name`, `Ticket`, `Cabin`)  

2. **Divis√£o em conjuntos**  
   - Separa√ß√£o de treino, valida√ß√£o e teste  

3. **Cria√ß√£o de DataLoaders**  
   - Prepara√ß√£o dos datasets em batches para treino e valida√ß√£o  

4. **Defini√ß√£o e treinamento dos modelos MLP**  
   - Arquiteturas comparativas: `Baseline`, `DeeperNet` e `WideNet`  
   - Fun√ß√µes de ativa√ß√£o: ReLU, LeakyReLU, Tanh  
   - Otimizadores: Adam, RMSprop  
   - Dropout e LayerNorm para regulariza√ß√£o  

5. **Monitoramento de m√©tricas**  
   - Loss (CrossEntropy) e acur√°cia para treino e valida√ß√£o  
   - Early stopping para evitar overfitting  
   - Scheduler de learning rate (`ReduceLROnPlateau`)  

6. **Avalia√ß√£o final e compara√ß√£o de modelos**  
   - Comparativo de loss e acur√°cia  
   - Evolu√ß√£o do learning rate  
   - Salvamento de modelos e hist√≥ricos  

---

## ‚öô Configura√ß√£o dos Modelos

Exemplo de configura√ß√£o de um modelo:

```python
{
    "name": "Baseline",
    "input_size": 9,
    "num_classes": 2,
    "layer_sizes": [64, 32],
    "activation_fn": nn.ReLU(),
    "dropout_rate": 0.3,
    "learning_rate": 1e-3,
    "optimizer": torch.optim.Adam,
    "n_epochs": 100,
    "bs_train": 32,
    "bs_val_test": 64,
    "loss_fn": nn.CrossEntropyLoss(),
    "patience": 10
}
